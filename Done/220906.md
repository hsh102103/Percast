# Q&A

- 역할 분담이 어떤지?

  - 우리가 생각한 서비스 중에 데이터분석이 들어가는 부분이 어디인지 잘 모르겠다.
  - 하둡이 사용되는 곳이 없는 것 같다. 정제할 피쳐가 없는 것 같다. 데이터 수집 이외의 정제 절차가 없다. → 하둡이 적절하지 않을 수 있다.
  - FE는 데이터 시각화 관련 스킬을 가장 많이 얻을 수 있다.
  - BE의 경우 서비스 BE는 1~2명이면 충분할 것 같다. 나머지 인원은 머신러닝 모델만들기, 데이터셋 수집을 담당하는 것이 좋다고 생각한다. DB의 경우 서비스DB에 대해서만 생각을 할 수 있고, 데이터셋 수집의 경우에도 관련있는 DB에 대해 고민하는 등의 각자 담당하는 부분을 나누는 것이 좋을 것 같다.

- 100만개 데이터면 부족한가?

  - 하둡은 크기보다는 처리량과 목적이 중요함. 실질적인 하둡의 사용 사례를 보려면 몇 십~ 몇 백 기가의 데이터가 되어야한다. 하둡을 경험에 보겠다는 취지이면 괜찮을 수 있다고 판단은 되나, 실무에서는 하둡이 손해를 보는 서비스이다. 만약 이 서비스를 가지고 면접을 보게된다면, ‘왜 하둡을 썼는가’에 대한 질문이 들어올 수 있고, 그때 학습을 목표로 했다고 한다면, 깊이 있는 개념에 대한 설명이 필요할 것 같다.
  - 기본적으로 클러스터를 셋업해놓고 사용하는 환경이다 보니, 하둡을 지속적으로 관리해줘야 하기 때문에 비용적인 측면에서 손해를 볼 수 있다.

- 현업에서 하둡이 사용되는 사례

  - HDFS와 스파크가 가장 많이 사용되고, 멀리가면 HBase까지. 핸들링 관련으로 사용할 만한 스파크로 데이터를 간단하게 정제하고 학습을 시키는 방향으로 사용 가능하다.

- 성능 비교 툴관련 질문

  - 성능 비교 툴은 따로 있지 않다. ex) 일반 파이썬으로 구현을 하고 하둡을 사용한 구현을 비교하는 방식은 있다.

- 하둡 클러스터 사용 방법

  - 싱글노드 클러스터 분산처리의 효율성을 보려면 컴퓨터를 여러개 사용하는 것이 좋을 것 같은데 클라우드가 지원이 된다면 클라우드에 사용하는 것이 훨씬 좋고, 여러 인스턴스 위에
  - 도저히 ec2에 띄우는 것이 힘들다면 ec2위에 standalone모드로 띄우는 것도 방법.

- 기획된 서비스에서의 고민 점

  어떻게 하면 방대한 데이터에서 추상적인 인사이트를 얻을 수 있는지에 대해 고민하고, 더 복잡한 니즈를 어드레스하려면 어떻게 하는 것이 좋을까 생각해 보는 것이 좋을 것 같다. 인간의 뇌로는 추상적으로 밖에 할 수 없는 것을 구체적으로 만드는 서비스.